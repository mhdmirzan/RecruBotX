"""Advanced Voice Agent using Premium Services
- Uses Deepgram Nova-2 for Speech-to-Text (superior accuracy)
- Uses Deepgram Aura for Text-to-Speech (natural voice)
- Uses Google Gemini for question generation
- Uses Hugging Face for answer evaluation
"""

import os
import threading
import textwrap
from dotenv import load_dotenv
import sounddevice as sd
import soundfile as sf
import requests
import json
import google.generativeai as genai
import numpy as np
from reportlab.lib.pagesizes import letter
from reportlab.pdfgen import canvas
from deepgram import DeepgramClient
from deepgram.extensions.types.sockets import (
    ListenV1ControlMessage,
    ListenV1ResultsEvent,
)

# Load environment variables from .env file
load_dotenv()

class VoiceAgent:
    FIELDS = [
        "Software Engineering",
        "Data Science",
        "Web Development",
        "Machine Learning",
        "DevOps",
        "Cybersecurity",
        "Mobile Development",
        "Database Administration",
        "Cloud Computing",
        "UI/UX Design",
        "Network Administration",
        "Data Engineering",
        "AI/ML Operations",
        "Site Reliability Engineering",
        "Security Operations",
        "Embedded Systems",
        "Game Development",
        "Blockchain Development",
        "IT Support",
        "AR/VR Development",
    ]

    LEVELS = ["Junior", "Intermediate", "Senior"]
    
    # Field-specific core topics for 80/20 rule
    FIELD_TOPICS = {
        "Software Engineering": ["OOP", "data structures", "algorithms", "design patterns", "testing", "version control", "code quality", "debugging"],
        "Data Science": ["statistics", "machine learning", "data cleaning", "visualization", "Python/R", "SQL", "model evaluation", "feature engineering"],
        "Web Development": ["HTML/CSS", "JavaScript", "REST APIs", "databases", "authentication", "frontend frameworks", "backend", "deployment"],
        "Machine Learning": ["supervised learning", "unsupervised learning", "neural networks", "model training", "overfitting", "feature selection", "evaluation metrics", "deep learning"],
        "DevOps": ["CI/CD", "Docker", "Kubernetes", "cloud platforms", "monitoring", "infrastructure as code", "automation", "security"],
        "Cybersecurity": ["encryption", "authentication", "vulnerabilities", "firewalls", "penetration testing", "security protocols", "incident response", "compliance"],
    }
    
    def __init__(self, interview_field=None, num_questions=None, position_level=None):
        print("Initializing Voice Agent...")
        
        # Configure Deepgram API
        deepgram_key = os.getenv('DEEPGRAM_API_KEY')
        if not deepgram_key:
            print("\n‚ö†Ô∏è DEEPGRAM_API_KEY not found in environment variables.")
            print("Please get a free API key from: https://console.deepgram.com/signup")
            deepgram_key = input("Enter your Deepgram API key: ").strip()
        
        self.deepgram = DeepgramClient(api_key=deepgram_key)
        
        # Configure Google Gemini API
        gemini_key = os.getenv('GEMINI_API_KEY')
        if not gemini_key:
            print("\n‚ö†Ô∏è GEMINI_API_KEY not found in environment variables.")
            print("Please get a free API key from: https://makersuite.google.com/app/apikey")
            gemini_key = input("Enter your Gemini API key: ").strip()
        
        genai.configure(api_key=gemini_key)
        self.gemini_model = genai.GenerativeModel('gemini-2.5-flash')
        
        print("Voice Agent initialized successfully!\n")
        print("Note: Using Deepgram Nova-2 (STT), Deepgram Aura (TTS), and Gemini 2.5 Flash (Questions & Evaluation)\n")
        
        # Get interview configuration from user
        if interview_field is None:
            self.interview_type = self._get_interview_field()
        else:
            self.interview_type = interview_field
        
        if position_level is None:
            self.position_level = self._get_position_level()
        else:
            self.position_level = position_level
            
        if num_questions is None:
            self.max_questions = self._get_num_questions()
        else:
            self.max_questions = num_questions
        
        self.question_count = 0
        self.interview_data = {
            "questions": [],
            "answers": [],
            "feedback": [],
            "scores": []
        }
        
        # Questions will be generated by LLM on-the-fly
        self.interview_questions = []
        self.asked_topics = []  # Track topics to avoid repetition
        self.last_report_path = None
    
    def _get_interview_field(self):
        """Get interview field from user"""
        print("\n" + "="*60)
        print("AVAILABLE INTERVIEW FIELDS:")
        print("="*60)
        fields = [
            "Software Engineering",
            "Data Science",
            "Web Development",
            "Machine Learning",
            "DevOps",
            "Cybersecurity",
            "Mobile Development",
            "Database Administration",
            "Cloud Computing",
            "UI/UX Design",
            "Network Administration",
            "Data Engineering",
            "AI/ML Operations",
            "Site Reliability Engineering",
            "Security Operations",
            "Embedded Systems",
            "Game Development",
            "Blockchain Development",
            "IT Support",
            "AR/VR Development"
        ]
        
        for i, field in enumerate(fields, 1):
            print(f"{i}. {field}")
        
        while True:
            try:
                choice = input("\nEnter the number of your interview field (or type custom field): ")
                if choice.isdigit() and 1 <= int(choice) <= len(fields):
                    return fields[int(choice) - 1]
                elif choice.strip():
                    return choice.strip()
            except:
                pass
            print("Invalid choice. Please try again.")
    
    def _get_position_level(self):
        """Get position level from user"""
        print("\n" + "="*60)
        print("SELECT POSITION LEVEL:")
        print("="*60)
        print("1. Junior (0-2 years experience)")
        print("2. Intermediate (2-5 years experience)")
        print("3. Senior (5+ years experience)")
        
        while True:
            try:
                choice = input("\nEnter the position level (1-3): ").strip()
                if choice == "1":
                    return "Junior"
                elif choice == "2":
                    return "Intermediate"
                elif choice == "3":
                    return "Senior"
                print("Invalid choice. Please enter 1, 2, or 3.")
            except:
                print("Invalid input. Please try again.")
    
    def _get_num_questions(self):
        """Get number of questions from user"""
        while True:
            try:
                num = input(f"\nHow many questions would you like (1-10)? ")
                num = int(num)
                if 1 <= num <= 10:
                    return num
                print("Please enter a number between 1 and 10.")
            except:
                print("Invalid input. Please enter a number.")
    
    def record_audio(self, max_duration=60, sample_rate=16000, silence_duration=4.0):
        """Record audio until 4s of silence or max_duration (VAD-style)"""
        print(f"üé§ Recording... (up to {max_duration}s, stops after {silence_duration}s silence)")
        chunk_ms = 500
        chunk_samples = int(sample_rate * chunk_ms / 1000)
        max_samples = int(max_duration * sample_rate)
        silence_ms = 0
        silence_threshold = 200  # adjust if needed for environment
        frames = []

        try:
            with sd.InputStream(samplerate=sample_rate, channels=1, dtype='int16') as stream:
                total = 0
                while total < max_samples:
                    chunk, _ = stream.read(chunk_samples)
                    frames.append(chunk)
                    total += len(chunk)
                    rms = np.mean(np.abs(chunk))
                    if rms < silence_threshold:
                        silence_ms += chunk_ms
                    else:
                        silence_ms = 0
                    if silence_ms >= silence_duration * 1000 and total > sample_rate * 1:
                        break
            audio = np.concatenate(frames, axis=0)
            actual_duration = len(audio) / sample_rate
            print(f"‚úì Recording complete ({actual_duration:.1f}s)")
            return audio, sample_rate
        except Exception as e:
            print(f"‚ö†Ô∏è Recording error: {e}")
            return np.zeros((1,), dtype='int16'), sample_rate
    
    def speech_to_text(self, max_duration=60, sample_rate=16000, silence_duration=4.0):
        """Stream mic audio to Deepgram STT until 4s silence or max_duration"""
        print("üîÑ Streaming speech to text with Deepgram Nova-2...")
        chunk_ms = 250
        chunk_samples = int(sample_rate * chunk_ms / 1000)
        max_samples = int(max_duration * sample_rate)
        silence_ms = 0
        silence_threshold = 200
        transcripts = []

        try:
            with self.deepgram.listen.v1.connect(
                model="nova-2",
                smart_format="true",
                punctuate="true",
                encoding="linear16",
                sample_rate=str(sample_rate),
                interim_results="true",
            ) as ws:
                def listen_ws():
                    for message in ws:
                        if isinstance(message, ListenV1ResultsEvent):
                            alt = message.channel.alternatives[0]
                            if message.speech_final or message.is_final:
                                if alt.transcript:
                                    transcripts.append(alt.transcript.strip())

                listener = threading.Thread(target=listen_ws, daemon=True)
                listener.start()

                with sd.InputStream(samplerate=sample_rate, channels=1, dtype="int16") as stream:
                    total = 0
                    while total < max_samples:
                        chunk, _ = stream.read(chunk_samples)
                        total += len(chunk)
                        ws.send_media(chunk.tobytes())

                        rms = np.mean(np.abs(chunk))
                        silence_ms = silence_ms + chunk_ms if rms < silence_threshold else 0
                        if silence_ms >= silence_duration * 1000 and total > sample_rate:
                            break

                try:
                    ws.send_control(ListenV1ControlMessage(type="Finalize"))
                except Exception:
                    pass

                listener.join(timeout=2.0)

            transcript = " ".join(transcripts).strip()
            if not transcript:
                transcript = "I couldn't understand that."

            print(f"üìù You said: {transcript}")
            return transcript
        except Exception as e:
            print(f"‚ö†Ô∏è Speech recognition error: {e}")
            return "Error processing speech"
    
    def generate_question(self):
        """Generate interview question using Gemini based on position level with duplicate prevention"""
        max_retries = 3
        
        for attempt in range(max_retries):
            # Build context about previously asked questions to prevent repetition
            previous_questions = "\n".join([f"- {q}" for q in self.interview_data["questions"]]) if self.interview_data["questions"] else "None yet"
            previous_topics = ", ".join(self.asked_topics) if self.asked_topics else "none"
            
            # Define difficulty requirements based on position level
            difficulty_guide = {
                "Junior": "Focus on fundamental concepts, basic terminology, and simple problem-solving. Expect clear explanations of core principles.",
                "Intermediate": "Focus on practical application, design patterns, best practices, and real-world scenarios. Expect detailed technical knowledge and experience-based insights.",
                "Senior": "Focus on system design, architecture decisions, scalability, trade-offs, leadership, and complex problem-solving. Expect deep expertise, critical thinking, and strategic understanding."
            }
            
            retry_note = f"\n\n‚ö†Ô∏è RETRY #{attempt + 1}: Previous attempt generated a duplicate. Generate a COMPLETELY DIFFERENT question on a NEW topic!" if attempt > 0 else ""
            
            # Get field-specific topics
            field_topics = self.FIELD_TOPICS.get(self.interview_type, ["core concepts", "best practices", "common tools"])
            topics_list = ", ".join(field_topics)
            
            prompt = f"""You are conducting a {self.interview_type} technical interview for a {self.position_level} level role.

Generate ONE concise, direct technical question for a {self.position_level} {self.interview_type} candidate.

Interview context:
- Position Level: {self.position_level}
- Interview Field: {self.interview_type}
- Question number: {self.question_count} of {self.max_questions}
- Difficulty guideline: {difficulty_guide[self.position_level]}

**MANDATORY FIELD RELEVANCE**: Question MUST be directly about {self.interview_type}. 
Core topics for {self.interview_type}: {topics_list}
Choose ONE of these topics or closely related concepts.

PREVIOUSLY ASKED QUESTIONS (NEVER REPEAT OR ASK SIMILAR):
{previous_questions}

Previously covered topics/concepts: {previous_topics}
{retry_note}

CRITICAL Requirements - MUST FOLLOW:
1. **80/20 RULE (MANDATORY)**: Focus on the 20% of core concepts that matter 80% of the time
   - Ask about FUNDAMENTAL, HIGH-IMPACT topics used daily in {self.interview_type}
   - Avoid obscure edge cases, rare scenarios, or overly niche topics
   - Prioritize practical, commonly-used concepts over theoretical rarities

2. **NO REPETITION (STRICT)**: 
   - NEVER ask about concepts already covered in previous questions
   - Ensure question is COMPLETELY DIFFERENT from all previous ones
   - Check against the list above and choose a FRESH, UNIQUE topic
   - If this is a retry, pick a totally different concept area

3. **CONCISENESS**: 
   - Keep question SHORT (12-18 words ideal, maximum 20 words)
   - Ask ONE specific concept only - no multi-part questions
   - Be direct, clear, and professional

4. **LEVEL-APPROPRIATE DIFFICULTY**:
   - Junior: fundamental definitions, basic concepts, "What is..."
   - Intermediate: practical application, "When to use...", "How does... work?"
   - Senior: architecture/design, "How would you design...", "What are trade-offs..."

Examples of GOOD questions (80/20 rule + concise + diverse topics):
- Junior: "What is object-oriented programming?"
- Junior: "What is a RESTful API?"
- Intermediate: "When should you use async programming?"
- Intermediate: "How does dependency injection improve code?"
- Senior: "How would you design a high-availability system?"
- Senior: "What are trade-offs between microservices and monoliths?"

Return ONLY the short question text, ending with a question mark. No preamble, no explanations, no numbering."""
            
            print(f"ü§î Generating question {self.question_count} with Gemini... (attempt {attempt + 1}/{max_retries})")
            
            try:
                response = self.gemini_model.generate_content(prompt)
                question = response.text.strip()
                
                # Clean up the question
                question = question.split('\n')[0].strip()
                # Remove any numbering, quotes, or extra formatting
                question = question.lstrip('0123456789.-) "\'').strip()
                
                # Ensure it ends with a question mark
                if question and not question.endswith('?'):
                    question += '?'

                if question and len(question.split()) >= 2:
                    # Check for duplicate or very similar question
                    if self._is_duplicate_question(question):
                        print(f"‚ö†Ô∏è Duplicate detected: '{question}' - Regenerating...")
                        continue  # Try again
                    
                    # Question is unique, track it
                    self._extract_and_track_topic(question)
                    print(f"‚úÖ Question {self.question_count}/{self.max_questions} generated: {question}")
                    return question
                else:
                    raise Exception("Question too short or empty")
                    
            except Exception as e:
                print(f"‚ö†Ô∏è Gemini generation failed: {e}")
                if attempt < max_retries - 1:
                    continue  # Try again
        
        # All retries exhausted, use fallback with randomization
        print("‚ö†Ô∏è Max retries reached, using fallback question")
        return self._generate_fallback_question()
    
    def _is_duplicate_question(self, new_question):
        """Check if the new question is a duplicate or very similar to existing ones"""
        if not self.interview_data["questions"]:
            return False
        
        # Normalize the new question
        new_normalized = new_question.lower().replace('?', '').strip()
        new_words = set(new_normalized.split())
        
        for existing_q in self.interview_data["questions"]:
            existing_normalized = existing_q.lower().replace('?', '').strip()
            
            # Check for exact match
            if new_normalized == existing_normalized:
                return True
            
            # Check for high similarity (>70% word overlap)
            existing_words = set(existing_normalized.split())
            if len(new_words) > 0 and len(existing_words) > 0:
                overlap = len(new_words & existing_words)
                similarity = overlap / min(len(new_words), len(existing_words))
                if similarity > 0.7:
                    return True
        
        return False
    
    def _generate_fallback_question(self):
        """Generate a unique fallback question based on level and question count"""
        import random
        
        # Define diverse fallback questions by level
        fallbacks = {
            "Junior": [
                f"What is {self.interview_type}?",
                f"What are variables and data types in programming?",
                f"What is the difference between a class and an object?",
                f"What is a function or method?",
                f"What is version control?",
            ],
            "Intermediate": [
                f"How does exception handling work in your preferred language?",
                f"When should you use inheritance versus composition?",
                f"What are the benefits of code review?",
                f"How do you ensure code quality in a project?",
                f"What is the purpose of testing in software development?",
            ],
            "Senior": [
                f"How would you design a scalable microservices architecture?",
                f"What factors influence technology stack selection for enterprise systems?",
                f"How do you balance technical debt with feature development?",
                f"What strategies ensure high availability in distributed systems?",
                f"How would you lead a technical migration with minimal downtime?",
            ]
        }
        
        # Get available fallbacks for this level
        available = fallbacks.get(self.position_level, fallbacks["Intermediate"])
        
        # Filter out already asked questions
        unused = [q for q in available if not self._is_duplicate_question(q)]
        
        # If all used, just pick randomly
        if not unused:
            unused = available
        
        return random.choice(unused)
    
    def _extract_and_track_topic(self, question):
        """Extract and store the complete question to prevent exact or similar repetition"""
        # Store the full question for strict duplicate checking
        words = question.lower().replace('?', '').strip().split()
        
        # Extract key technical terms (nouns, verbs) for topic tracking
        stop_words = {'what', 'how', 'why', 'when', 'where', 'which', 'who', 'is', 'are', 'the', 'a', 'an', 
                      'explain', 'describe', 'define', 'tell', 'me', 'about', 'would', 'you', 'should', 'could',
                      'does', 'do', 'can', 'will', 'in', 'on', 'at', 'for', 'to', 'of', 'and', 'or', 'but'}
        
        tech_terms = [word for word in words if word not in stop_words and len(word) > 3]
        
        # Store top 3 key terms as the topic signature
        if tech_terms:
            topic_signature = " ".join(tech_terms[:3])
            self.asked_topics.append(topic_signature)
            print(f"üîñ Tracked topic: {topic_signature}")
    
    def analyze_answer(self, question, user_answer):
        """Analyze user's answer using Gemini Flash 2.5 for deep conceptual understanding evaluation (out of 100)"""
        print("üîç Analyzing answer with deep AI evaluation...")
        
        # STRICT CHECK: Detect silent/no answer cases
        if not user_answer or len(user_answer.strip()) < 5:
            score = 0
            feedback = "Score: 0/100 - No answer provided or silence detected."
            self.interview_data["scores"].append(score)
            return feedback
        
        # Check for error/couldn't understand responses
        if "couldn't understand" in user_answer.lower() or "error processing" in user_answer.lower():
            score = 0
            feedback = "Score: 0/100 - Audio not captured or incomprehensible response."
            self.interview_data["scores"].append(score)
            return feedback
        
        # Create advanced multi-step evaluation prompt for deep understanding assessment
        prompt = f"""You are a distinguished {self.interview_type} technical interviewer and educator with 20+ years of experience. Your expertise lies in assessing whether candidates truly UNDERSTAND concepts, not just memorize definitions.

INTERVIEW CONTEXT:
- Field: {self.interview_type}
- Position Level: {self.position_level}
- Question Asked: {question}
- Candidate's Answer: {user_answer}

YOUR EVALUATION TASK:
Assess the candidate's CONCEPTUAL UNDERSTANDING using rigorous, multi-dimensional analysis.

EVALUATION DIMENSIONS:

1. FACTUAL ACCURACY (40% weight)
   - Is the core information FACTUALLY CORRECT?
   - Any technical ERRORS or MISCONCEPTIONS?
   - Terminology used ACCURATELY?

2. DEPTH OF UNDERSTANDING (30% weight)
   - Shows GENUINE UNDERSTANDING vs surface recall?
   - Evidence: explains why/how, relationships, practical use
   - Cause-and-effect reasoning demonstrated?

3. COMPLETENESS & CLARITY (20% weight)
   - Addresses question fully and directly?
   - Clear, well-structured explanation?
   - Appropriate detail for {self.position_level}?

4. LEVEL-APPROPRIATENESS (10% weight)
   - Meets {self.position_level} expectations?
   - Junior: clear definitions | Intermediate: applied knowledge | Senior: strategic thinking

CRITICAL RULES:

‚ùå WRONG CONCEPT = max 39/100 (even if long answer)
‚ùå VAGUE/UNCERTAIN ("I think", "maybe") = max 55/100
‚ùå MEMORIZED WITHOUT UNDERSTANDING = max 65/100
‚ùå CIRCULAR DEFINITIONS or BUZZWORDS WITHOUT EXPLANATION = max 50/100
‚ùå CONFUSING SIMILAR CONCEPTS = max 45/100

‚úÖ CORRECT + BRIEF = 60-75/100
‚úÖ UNDERSTOOD + COMPLETE = 76-85/100
‚úÖ MASTERY DEMONSTRATED = 86-100/100

SCORING GUIDE:

**90-100**: MASTERY - Perfect accuracy + deep understanding + insights
**80-89**: STRONG - Correct + clear comprehension + good depth
**70-79**: GOOD - Core correct + shows understanding + adequate detail
**60-69**: BASIC - Main idea right + lacks depth or clarity
**50-59**: PARTIAL - Some correct + gaps or vagueness
**40-49**: WEAK - More gaps than understanding
**20-39**: INCORRECT - Fundamentally wrong or major errors
**0-19**: NO UNDERSTANDING - Nonsensical or completely wrong

ASSESS TRUE UNDERSTANDING, not word count. Provide ONE LINE:
Score: X/100 - [Brief reasoning about their understanding]

Example: "Score: 82/100 - Demonstrates strong conceptual understanding with accurate explanation and practical context, could add more depth on edge cases.\""""
        
        try:
            # Use Gemini to intelligently evaluate the answer with deep understanding assessment
            response = self.gemini_model.generate_content(prompt)
            feedback = response.text.strip()
            
            # Extract first meaningful line if multiple lines returned
            feedback_line = feedback.split('\n')[0].strip()
            if len(feedback_line) < 10 and len(feedback.split('\n')) > 1:
                feedback_line = feedback.split('\n')[1].strip()
            
            # Extract score from Gemini's response
            score = self._extract_score(feedback_line)
            self.interview_data["scores"].append(score)
            
            return feedback_line
            
        except Exception as e:
            print(f"‚ö†Ô∏è Gemini evaluation error: {e}")
            # Fallback: Check for no answer
            if not user_answer or len(user_answer.strip()) < 5:
                score = 0
                feedback = "Score: 0/100 - No substantial answer provided."
            else:
                score = 50
                feedback = "Score: 50/100 - Unable to evaluate with AI, manual review needed."
            
            self.interview_data["scores"].append(score)
            return feedback
    
    def _extract_score(self, feedback):
        """Extract numerical score from feedback (out of 100)"""
        import re
        # Try to find X/100 pattern
        match = re.search(r'(\d+(?:\.\d+)?)\s*/\s*100', feedback)
        if match:
            score = float(match.group(1))
            return min(100, max(0, int(round(score))))  # Ensure 0-100 range
        
        # Try to find standalone number (assume /100)
        match = re.search(r'\b(\d{1,3})\b', feedback)
        if match:
            score = int(match.group(1))
            if 0 <= score <= 100:
                return score
        
        # Default if no score found
        return 50
    
    # Old rule-based scoring methods removed - now using Gemini's intelligent evaluation
    
    def generate_report(self):
        """Generate comprehensive interview feedback report"""
        print("\n" + "="*60)
        print("üìä SOFTWARE ENGINEERING INTERVIEW REPORT")
        print("="*60 + "\n")
        
        total_score = sum(self.interview_data["scores"])
        avg_score = total_score / len(self.interview_data["scores"]) if self.interview_data["scores"] else 0
        
        print(f"üìã Interview Type: {self.interview_type}")
        print(f"üíº Position Level: {self.position_level}")
        print(f"üìù Total Questions: {len(self.interview_data['questions'])}")
        print(f"‚≠ê Overall Score: {avg_score:.1f}/100")
        print(f"üìà Performance Level: {self._get_performance_level(avg_score)}\n")
        
        print("-" * 60)
        print("DETAILED QUESTION-BY-QUESTION ANALYSIS")
        print("-" * 60 + "\n")
        
        for i in range(len(self.interview_data["questions"])):
            print(f"Question {i+1}:")
            print(f"  Q: {self.interview_data['questions'][i]}")
            print(f"  A: {self.interview_data['answers'][i]}")
            print(f"  Score: {self.interview_data['scores'][i]}/100")
            print(f"  Feedback: {self.interview_data['feedback'][i]}")
            print()
        
        print("-" * 60)
        print("OVERALL ASSESSMENT")
        print("-" * 60 + "\n")
        
        # Generate summary
        strengths, improvements = self._analyze_performance()
        
        print("üí™ Strengths:")
        for strength in strengths:
            print(f"  ‚Ä¢ {strength}")
        
        print("\nüéØ Areas for Improvement:")
        for improvement in improvements:
            print(f"  ‚Ä¢ {improvement}")
        
        print("\nüìå Recommendation:")
        print(f"  {self._get_recommendation(avg_score)}")
        
        print("\n" + "="*60)
        print("END OF REPORT")
        print("="*60 + "\n")
        
        # Save report to file
        return self._save_report_to_file(avg_score)
    
    def _get_performance_level(self, avg_score):
        """Determine performance level with stricter criteria (out of 100)"""
        if avg_score >= 85:
            return "üåü Excellent - Strong Candidate"
        elif avg_score >= 70:
            return "‚úÖ Good - Recommended"
        elif avg_score >= 55:
            return "‚ö†Ô∏è Fair - Needs Improvement"
        elif avg_score >= 40:
            return "‚ùå Below Standard - Not Recommended"
        else:
            return "‚ùå‚ùå Failing - Unacceptable Performance"
    
    def _analyze_performance(self):
        """Analyze strengths and weaknesses"""
        scores = self.interview_data["scores"]
        avg_score = sum(scores) / len(scores) if scores else 0
        
        strengths = []
        improvements = []
        
        # Handle case with no answers
        if not scores or len(self.interview_data["answers"]) == 0:
            improvements.append("Complete the interview to receive feedback")
            strengths.append("Started the interview process")
            return strengths, improvements
        
        # Analyze based on scores
        high_scores = [i for i, s in enumerate(scores) if s >= 7]
        low_scores = [i for i, s in enumerate(scores) if s < 5]
        
        if high_scores:
            # Get topics from interview questions (dynamic or pre-built)
            if self.interview_data["questions"]:
                topics = [self.interview_data["questions"][i].split('?')[0][:50] for i in high_scores if i < len(self.interview_data["questions"])]
            strengths.append(f"Performed well on {len(high_scores)} questions")
            if len(high_scores) >= 3:
                strengths.append("Demonstrated consistent knowledge")
        
        if avg_score >= 6:
            strengths.append(f"Good foundational understanding of {self.interview_type} concepts")
        
        if low_scores:
            improvements.append(f"Need to strengthen {len(low_scores)} topic areas")
            if self.interview_data["questions"]:
                for i in low_scores:
                    if i < len(self.interview_data["questions"]):
                        topic = self.interview_data["questions"][i].split()[0:6]
                        improvements.append(f"Review: {' '.join(topic)}")
        
        if avg_score < 6:
            improvements.append(f"Overall knowledge of {self.interview_type} fundamentals")
        
        # Analyze answer quality
        if self.interview_data["answers"]:
            avg_length = sum(len(a) for a in self.interview_data["answers"]) / len(self.interview_data["answers"])
            if avg_length < 30:
                improvements.append("Provide more detailed and elaborate answers")
            else:
                strengths.append("Good communication with detailed responses")
        
        if not strengths:
            strengths.append("Completed all interview questions")
        
        if not improvements:
            improvements.append("Continue building on existing knowledge")
        
        return strengths, improvements
    
    def _get_recommendation(self, avg_score):
        """Get strict hiring recommendation based on position level"""
        if self.position_level == "Senior":
            if avg_score >= 8.5:
                return f"Strong recommendation for {self.position_level} position. Demonstrates exceptional expertise and deep technical understanding."
            elif avg_score >= 7.5:
                return f"Conditional recommendation for {self.position_level} position. Shows good knowledge but needs to demonstrate more depth in certain areas."
            else:
                return f"Not recommended for {self.position_level} position. Consider intermediate role or further skill development."
        elif self.position_level == "Intermediate":
            if avg_score >= 8.0:
                return f"Strong recommendation for {self.position_level} position. Shows solid practical knowledge and problem-solving ability."
            elif avg_score >= 6.5:
                return f"Recommend for {self.position_level} position with initial mentorship. Has foundation but needs growth in some areas."
            else:
                return f"Not recommended for {self.position_level} position. Consider junior role or additional training."
        else:  # Junior
            if avg_score >= 7.0:
                return f"Strong recommendation for {self.position_level} position. Demonstrates good foundational understanding."
            elif avg_score >= 5.5:
                return f"Recommend for {self.position_level} position with close mentorship. Shows basic understanding with room for growth."
            else:
                return f"Not recommended at this time. Candidate should strengthen core fundamentals before reapplying."
    
    def _save_report_to_file(self, avg_score):
        """Save the interview report to text and PDF files"""
        import datetime

        # Create output directory if it doesn't exist
        output_dir = "output"
        os.makedirs(output_dir, exist_ok=True)

        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        txt_filename = os.path.join(output_dir, f"interview_report_{timestamp}.txt")
        pdf_filename = os.path.join(output_dir, f"interview_report_{timestamp}.pdf")

        # Build report lines once for reuse in txt + pdf
        lines = []
        header = "=" * 60
        lines.append(header)
        lines.append("SOFTWARE ENGINEERING INTERVIEW REPORT")
        lines.append(header)
        lines.append("")
        lines.append(f"Date: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append(f"Interview Type: {self.interview_type}")
        lines.append(f"Position Level: {self.position_level}")
        lines.append(f"Total Questions: {len(self.interview_data['questions'])}")
        lines.append(f"Overall Score: {avg_score:.1f}/100")
        lines.append(f"Performance Level: {self._get_performance_level(avg_score)}")
        lines.append("")
        lines.append("_" * 60)
        lines.append("DETAILED ANALYSIS")
        lines.append("_" * 60)
        lines.append("")

        for i in range(len(self.interview_data["questions"])):
            lines.append(f"Question {i+1}:")
            lines.append(f"  Q: {self.interview_data['questions'][i]}")
            lines.append(f"  A: {self.interview_data['answers'][i]}")
            lines.append(f"  Score: {self.interview_data['scores'][i]}/100")
            lines.append(f"  Feedback: {self.interview_data['feedback'][i]}")
            lines.append("")

        strengths, improvements = self._analyze_performance()
        lines.append("_" * 60)
        lines.append("STRENGTHS:")
        if strengths:
            for strength in strengths:
                lines.append(f"  - {strength}")
        else:
            lines.append("  - None recorded")

        lines.append("")
        lines.append("AREAS FOR IMPROVEMENT:")
        if improvements:
            for improvement in improvements:
                lines.append(f"  - {improvement}")
        else:
            lines.append("  - None recorded")

        lines.append("")
        lines.append("RECOMMENDATION:")
        lines.append(f"  {self._get_recommendation(avg_score)}")
        lines.append("")
        lines.append(header)

        try:
            with open(txt_filename, "w", encoding="utf-8") as f:
                for line in lines:
                    f.write(line + "\n")

            # Generate PDF using ReportLab
            c = canvas.Canvas(pdf_filename, pagesize=letter)
            width, height = letter
            x_margin = 54
            y = height - 72
            line_height = 14

            for line in lines:
                if line == "":
                    y -= line_height
                else:
                    wrapped = textwrap.wrap(line, width=90)
                    if not wrapped:
                        wrapped = [line]
                    for segment in wrapped:
                        c.drawString(x_margin, y, segment)
                        y -= line_height
                        if y < 72:
                            c.showPage()
                            y = height - 72
                if y < 72:
                    c.showPage()
                    y = height - 72

            c.save()
            self.last_report_path = pdf_filename
            print(f"‚úÖ Report saved to: {txt_filename} and {pdf_filename}")
            return pdf_filename
        except Exception as e:
            print(f"‚ö†Ô∏è Could not save report to file: {e}")
            return None
    
    def text_to_speech(self, text, sample_rate=24000):
        """Generate WAV via REST TTS then play (non-streaming to avoid beeps)"""
        print("üîä Speaking...")
        temp_path = "tts_output.wav"
        try:
            audio_iter = self.deepgram.speak.v1.audio.generate(
                text=text,
                model="aura-asteria-en",
                encoding="linear16",
                sample_rate=sample_rate,
                container="wav",
            )

            with open(temp_path, "wb") as f:
                for chunk in audio_iter:
                    f.write(chunk)

            data, sr = sf.read(temp_path, dtype="int16")
            sd.play(data, sr)
            sd.wait()
            print(f"üí¨ {text}")
        except Exception as e:
            print(f"‚ö†Ô∏è TTS playback error: {e}")
            print(f"üí¨ {text}")
        finally:
            try:
                if os.path.exists(temp_path):
                    os.remove(temp_path)
            except Exception:
                pass
    
    def introduce_interview(self):
        """Speak the initial interview introduction with details"""
        intro = f"Hello and welcome to your interview. Today, we will be conducting a {self.interview_type} interview for a {self.position_level} position. I will ask you {self.max_questions} questions. Please answer each question clearly and to the best of your ability. Let's begin!"
        print(f"\nü§ñ INTRODUCTION: {intro}\n")
        self.text_to_speech(intro)
    
    def run(self):
        """Main interview conversation loop"""
        # Introduce the interview with voice
        self.introduce_interview()
        
        while self.question_count < self.max_questions:
            self.question_count += 1
            print(f"\n--- Question {self.question_count}/{self.max_questions} ---")
            
            # Get interview question
            question = self.generate_question()
            if question is None:
                break
                
            self.interview_data["questions"].append(question)
            print(f"Q{self.question_count}: {question}")
            
            # Speak the question directly (no pre-print to reduce latency)
            self.text_to_speech(question)
            print(f"\n(Question {self.question_count}/{self.max_questions} spoken)\n")
            
            # Stream user's answer with VAD stop (4s silence, max 60s)
            user_answer = self.speech_to_text(max_duration=60, sample_rate=16000, silence_duration=4.0)
            self.interview_data["answers"].append(user_answer)
            
        # Analyze all answers at once to avoid per-question delays
        for q, a in zip(self.interview_data["questions"], self.interview_data["answers"]):
            feedback = self.analyze_answer(q, a)
            self.interview_data["feedback"].append(feedback)

        # Closing message (concise to reduce gap)
        closing = "All questions completed. Generating your detailed feedback now."
        print(f"\nü§ñ {closing}\n")
        self.text_to_speech(closing)
        
        # Generate comprehensive report
        self.generate_report()

        # Speak concise feedback summary
        try:
            avg_score = sum(self.interview_data["scores"]) / len(self.interview_data["scores"]) if self.interview_data["scores"] else 0
            strengths, improvements = self._analyze_performance()
            top_strength = strengths[0] if strengths else "Completed the interview"
            top_improvement = improvements[0] if improvements else "Keep practicing"
            summary_voice = f"Your interview is complete. Average score {avg_score:.1f} out of 100. Strength: {top_strength}. Priority improvement: {top_improvement}. Report saved for download."
            self.text_to_speech(summary_voice)
        except Exception as e:
            print(f"‚ö†Ô∏è Could not speak summary: {e}")
        
        # Final message
        final = "Your interview report has been generated. Thank you and good luck!"

        self.text_to_speech(final)


if __name__ == "__main__":
    try:
        agent = VoiceAgent()
        agent.run()
    except KeyboardInterrupt:
        print("\n\nSession interrupted by user. Goodbye!")
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
